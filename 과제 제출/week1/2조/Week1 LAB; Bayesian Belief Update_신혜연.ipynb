{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 1 1 0 0 0 0 1 1]\n",
      "15\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Lab을 python으로 따라해보기 - Week1 LAB: Bayesian Belief Update\n",
    "####ESC 2020 - 1 신혜연\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "import pandas as pd\n",
    "pd.set_option('display.precision', 3)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Case1: Beta-Bonimal (unknown p)\n",
    "from scipy.stats import binom, beta\n",
    "###Sampling Density\n",
    "####Every statistical inference or prediction should always start first with the assumption on sampling density, i.e. data generating process. In this case, we have a data set from a classical coin toss, yi∈{0,1} yi∈{0,1}, where yi=1with a probability p, and our goal is to make Bayesian inference on the parameter p.\n",
    "\n",
    "# population parameter\n",
    "p = 0.3\n",
    "# generate toy sample\n",
    "N = 15\n",
    "np.random.seed(101)\n",
    "data = binom.rvs(1,p, size=N)\n",
    "print(data)\n",
    "print(data.size)\n",
    "print(data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prior Belief\n",
    "#### Prior belief can be in any form (flat, peaked, skewed, bimodal...) as long as the belief satistifies the fundamental axioms of probability. We choose beta distribution to express our belief solely because of its analytic convenience, that is, the resulting posterior can be integrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0247dfd22163>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'beta' is not defined"
     ]
    }
   ],
   "source": [
    "# choose your belief parameter\n",
    "a= 7; b= 2\n",
    "\n",
    "prior = beta(a, b)\n",
    "theta = np.linspace(0,1,100)\n",
    "plt.plot(prior.pdf(theta), color='r')\n",
    "plt.title('beta prior')\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('p(theta)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can always reflect other belief by tweaking your parameter;\n",
    "a2= 3; b2= 10\n",
    "\n",
    "prior2 = beta(a2, b2)\n",
    "theta = np.linspace(0,1,100)\n",
    "plt.plot(prior2.pdf(theta), color='r')\n",
    "plt.title('beta prior2')\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('p(theta)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Likelihood (Sampling Density)\n",
    "####Once you have specified your belief, you need to consider \"how likely\" the data is at each point of p. What you would really come in handy is a plot where every possible choice of p is on x-axis and the y-axis shows \"how likely the data came from that choice of p. Likelihood does exactly this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6abe59d563a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msuc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msuc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# note that we neglected the constant as it will be canceled out in appling Bayes Rule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"likelihood\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"theta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# scipy stats package does not allow for plotting pdf-theta so we need to define formula directly.\n",
    "def likelihood(D, p):\n",
    "    N = D.size; suc = D.sum()\n",
    "    theta = np.linspace(0,1,100)\n",
    "    return p**suc * (1-p)**(N-suc) # note that we neglected the constant as it will be canceled out in appling Bayes Rule\n",
    "\n",
    "plt.plot(theta, likelihood(data, theta), color='g')\n",
    "plt.title(\"likelihood\")\n",
    "plt.xlabel(\"theta\")\n",
    "plt.ylabel(\"p(Data|theta)\")\n",
    "plt.ylim(0,0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Posterior: Updated Belief\n",
    "#### The posterior is defined by strictly applying Bayes Rule;. This is in most cases analytically intractable, but in this case where we have a conjugacy between the belief distribution and the sampling distribution, this simply reduces to updating belief paratemers; a, b. Otherwise we have to approximate p(θ|D) or use numerical methods, such as MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a1e993828349>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# beta일 때 Belief update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mb_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mposterior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# beta일 때 Belief update\n",
    "a_pos = a + data.sum()\n",
    "b_pos = b + data.size - data.sum()\n",
    "\n",
    "posterior = beta(a_pos, b_pos)\n",
    "theta = np.linspace(0,1,100)\n",
    "plt.plot(posterior.pdf(theta), color='r')\n",
    "plt.title('beta posterior')\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('p(theta)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-358a6311a0c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# in a nutshell;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m131\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# in a nutshell;\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.plot(prior.pdf(theta), color='r')\n",
    "ax1.set_title('prior')\n",
    "ax1.set_xlabel('theta')\n",
    "ax1.set_ylim(0,4)\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.plot(theta, likelihood(data, theta), color='g')\n",
    "ax2.set_title('likelihood')\n",
    "ax2.set_xlabel('theta')\n",
    "ax2.set_ylim(0,0.0005)\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.plot(posterior.pdf(theta), color='r')\n",
    "ax3.set_title('posterior')\n",
    "ax3.set_xlabel('theta')\n",
    "ax3.set_ylim(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "## Case 2: Gaussian(prior) -Gaussian(likelihood) with (unknown mu known precision)\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import numpy as np\n",
    "###Sampling Density\n",
    "mu = 18 ; sigma = 3\n",
    "\n",
    "### generate data sample\n",
    "# (18,3)인 정규확률분포를 따르는 N=100개의 데이터를 얻었다고 하자. \n",
    "N = 100\n",
    "np.random.seed(100)\n",
    "data = norm.rvs(loc=mu,scale=sigma, size=N) \n",
    "xbar = np.mean(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prior Belief\n",
    "#### Let Prior belief as norm. (모수와 데이터는 내 마음대로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-001fdf5d319c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu_pr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prior on mu (mu=17,sd = 2)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# choose your belief parameter\n",
    "mu_pr = 17; sd_pr = 2 ; var_pr = sd_pr**2\n",
    "prior = norm(mu_pr, sd_pr)\n",
    "\n",
    "mu = np.linspace(0,30,100) \n",
    "plt.plot(mu, prior.pdf(mu), color='r')\n",
    "plt.vlines(mu_pr, ymin = 0, ymax=np.max(prior.pdf(mu)), colors = 'blue')\n",
    "plt.title('Prior on mu (mu=17,sd = 2)')\n",
    "plt.xlabel('mu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Likelihood (Sampling Density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the date\n",
    "def loglikelihood(D, x):\n",
    "    N = D.size\n",
    "    value = 0\n",
    "    for i in D:\n",
    "        value = value + np.log(norm.pdf(i, x, 1))\n",
    "    return value\n",
    "\n",
    "plt.plot(mu,loglikelihood(data, mu), color='g')\n",
    "plt.title(\"log likelihood\")\n",
    "plt.xlabel(\"mu\")\n",
    "plt.vlines(xbar, ymin = -16000, ymax=loglikelihood(data,xbar), colors = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Posterior: Updated Belief\n",
    "#### The posterior is defined by strictly applying Bayes Rule;. This is in most cases analytically intractable, but in this case where we have a conjugacy between the belief distribution and the sampling distribution, this simply reduces to updating belief paratemers; a, b. Otherwise we have to approximate p(θ|D) or use numerical methods, such as MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Belief update\n",
    "\n",
    "var_pos = 1 / (1/(sd_pr**2) + N/np.var(data))\n",
    "mu_pos = (mu_pr/(sd_pr**2) + N*xbar/np.var(data))*var_pos\n",
    "sd_pos = np.sqrt(var_pos)\n",
    "\n",
    "posterior = norm(mu_pos, sd_pos)\n",
    "xx = np.linspace(0, 30, 100)\n",
    "plt.plot(xx, posterior.pdf(xx), color='r')\n",
    "plt.title('Posterior on mu (mu=17,xbar=17.7)')\n",
    "plt.vlines(mu_pr, ymin = 0, ymax=np.max(posterior.pdf(xx)), colors = 'orange')\n",
    "plt.vlines(mu_pos, ymin = 0, ymax=np.max(posterior.pdf(xx)), colors = 'blue')\n",
    "plt.xlabel('mu')\n",
    "plt.ylabel('p(mu)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# in a nutshell;\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.plot(mu, prior.pdf(mu), color='r')\n",
    "ax1.set_title('Prior')\n",
    "ax1.set_xlabel('mu')\n",
    "ax1.vlines(mu_pr, ymin = 0, ymax=np.max(prior.pdf(mu)), colors = 'blue')\n",
    "ax1.set_ylim(0,0.3)\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.plot(mu, loglikelihood(data, mu), color='g')\n",
    "ax2.set_title('loglikelihood')\n",
    "ax2.set_xlabel('mu')\n",
    "ax2.vlines(xbar, ymin = -16000, ymax=loglikelihood(data,xbar), colors = 'blue')\n",
    "ax2.set_ylim(-17000,0.1)\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.plot(xx, posterior.pdf(xx), color='r')\n",
    "ax3.set_title('Posterior on mu (mu=17,xbar=17.7)')\n",
    "ax3.vlines(mu_pr, ymin = 0, ymax=np.max(posterior.pdf(xx)), colors = 'orange')\n",
    "ax3.vlines(mu_pos, ymin = 0, ymax=np.max(posterior.pdf(xx)), colors = 'blue')\n",
    "ax3.set_xlabel('mu')\n",
    "ax3.set_ylim(0,1.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
